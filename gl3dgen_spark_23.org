#+AUTHOR: phdenzel
#+TITLE: Deep generative modelling for gravitational lensing fields from 3D models of galaxies
# Generating gravitational lensing deflection fields from 3D models of galaxies using deep learning for mock observations
#+DATE: 2023-04-26 Wed
#+OPTIONS: author:nil title:t date:nil timestamp:nil toc:nil num:t \n:nil
#+LATEX_CLASS_OPTIONS: [a4paper,10pt]
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \newgeometry{top=1in,bottom=1in,right=1.125in,left=1.125in}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \onehalfspacing
#+LATEX_HEADER: \usepackage{titling}
#+LATEX_HEADER: \setlength{\droptitle}{-0.75in}
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \usepackage{makeidx}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{cleveref}
#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{parskip}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \usepackage{bm}

#+LATEX: \vspace{-0.8in}
** Project summary

Gravitational lensing is a phenomenon that occurs when rays of light
from a distant background source are deflected by the gravitational
field of a massive foreground object, e.g. a galaxy, which almost
perfectly aligns with the observer. While such occurrences are rare,
they are scientifically significant, because they provide the only
opportunity to directly infer the lensing galaxy's mass distribution,
including its dark matter content.  This unique perspective on a
galaxy's dark matter distribution offers exceptional insights into the
mysteries surrounding galaxy evolution, the nature of dark matter,
galaxy substructures, and even the expansion of the Universe. \\
Accurately predicting the deflection field of a strong gravitational
lens is a complex task that requires a detailed understanding of the
distribution of matter in the lensing galaxy. Conventional methods for
calculating these deflection fields, such as ray-tracing, are
computationally expensive, can take a long time to generate results,
and typically have to be fine-tuned by an experienced expert.

In recent years, deep learning methods have emerged as a promising
approach for generating and processing image-based data in various
scientific fields, often with super-human proficiency. These methods
employ neural networks to learn the mapping between the input
properties (for instance, the lensing galaxy) and the resulting image
(in this instance, the deflection field).

In this research proposal, I outline the usage of generative deep
learning methods to produce strongly lensing deflection fields of 3D
galaxy models from existing hydrodynamical simulation suites for the
purpose of creating mock observations, observational fits, and
corresponding source reconstructions. Specifically, we will explore
various state-of-the-art deep learning architectures, including
diffusion models, flow-based models, generative adversarial networks
(GANs), and variational autoencoders (VAEs) to develop a model that
can accurately generate the deflection field from a given 3D galaxy
model. The resulting deep learning model will be used to create
synthetic observations that can be compared to existing observational
data to test the accuracy of the lens model, and in particular
investigate the theoretical properties of the observed lensing
galaxies and their corresponding background source reconstructions,
within a Bayesian framework.

Lens modelling is inherently considered as a (degenerate) 2D inverse
problem. The novelty of this project consists of introducing 3D models
as direct input, which requires methods able to cover a broad range in
solution space due to the degeneracy introduced thereby. Conventional
modelling methods are insufficient due to the typically low complexity
of their models whereas deep learning methods increase the model
complexity with a high number of parameters, thus able to span a wider
range in solution space.

As of today, roughly 10^3 lenses have been discovered, only a fraction
of those properly analysed. Moreover, it is anticipated that the
next-generation satellites and telescopes such as
JWST\footnote{James~Webb~Space~Telescope}, Euclid,
SKA\footnote{Square~Kilometer~Array}, or
ELT\footnote{Extremely~Large~Telescope} may increase this number to
10^5. Thus, it is crucial to devise novel techniques that can scale
with big data efficiently.


#+LATEX: \newpage
** Project plan

*** State of research
<<sec:research>>

Although gravitational lensing is often regarded as an optical
illusion that shows the same source in multiple images, lensing
systems possess distinct visual features which make them relatively
easy to spot by the trained eye. Nevertheless, wide-field surveys
capture billions of light sources, and over 100'000 strongly lensing
systems may still await discovery
[[citep:&Taak20;&Taak23;&Collett15]]. Not all these instances can be
examined by humans with the same level of scrutiny. \\
Deep learning methods have emerged as a promising approach for the
automated detection of strong gravitational lenses. In fact, recent
studies have demonstrated that deep learning techniques have led to a
significant increase in the number of identified strong lensing
candidates by more than threefold
[[citep:&Storfer22;&Huang21;&Rezaei22;&Wilde22]].

Contrary to the automated discovery of strong gravitational lenses
using deep learning, advancements for lens modelling have been more
restrained in that aspect. Still, the scientific community is actively
investigating how deep learning can be integrated into lens
modelling. \\
In a recent study by [[cite:&Gu22]], the same optimization methods
utilized in the backward propagation algorithm for training neural
networks were employed in a Bayesian framework. Through a Hamiltonian
Monte-Carlo sampling scheme, they obtained posterior estimates for
their lens model parameters, albeit with mediocre efficiency. Based on
the previous study, [[cite:&Mishra-Sharma22]] use continuous neural
fields to reconstruct strongly lensing sources from parametric lens
models. \\
Similarly, [[cite:&Morningstar19]] designed a custom recurrent neural
network (RNN) architecture, the recurrent inference machine (RIM), to
construct reconstructed source priors for fitting lens model
parameters. A subsequent study by [[cite:&Adam22]] incorporates the
lens modelling procedure in the RIM architecture. \\
In an automated pipeline setting, [[cite:&Schuldt22;&Chianese19]]
demonstrate that incorporating a simple CNN-based residual network
(ResNet) for estimating lens model parameters is comparable in
performance to traditional parametric lens modelling techniques. \\
Furthermore, [[cite:&Park20]] use a Bayesian neural network (BNN) to
characterize the posterior probabilities of lens model parameters for
the purpose of inferring the Hubble constant.

The very first gravitational lens discovered by [[cite:&Walsh79]] was
simultaneously confirmed and modelled by [[cite:&Young80]]. They used
a simple spherically symmetric lens model using 4 parameters to fit
the observation. Ever since then, even modern lens modelling tools (as
mentioned above) employ some type of parametric model (with typically
no more than 8 parameters) to fit the density distribution of the lens
[[citep:cf.&Birrer18;&Hezaveh17;&Tessore16;&Oguri10]]. Note that
[[cite:&Hezaveh17]] use convolutional neural networks (CNNs) to fit
mass distribution parameters to lens observations. However, this still
prescribes the same parametric constraints on the complexity of the
lensing galaxy's shape.

[[cite:&Young81]] already recognized that a major obstacle in lens
modelling is that numerous mass distributions could plausibly explain
observed data. This fact manifests as parameter degeneracies when
interpreting observations as discussed by
[[cite:&Saha00;&Saha06;&Schneider14;&Birrer21]].  An often ignored issue
with parametric models is that they assume to cover enough of the
solution space to encompass the "truth".  Cognizant of this fact,
free-form lens modelling, as presented by [[citep:&Saha04]], uses an
over-parameterization trick to sample a wide range of solution
space. Despite, this technique is not efficient at higher resolutions
and the majority of fits are still not considered realistic or
physically viable.

All conventional lens modelling techniques rely on recipes which aim
to efficiently reproduce shapes and slopes of galaxies, as they are
usually observed. These methods therefore suppress or even completely
ignore the evolutionary processes of galaxies and the physical
properties which form and drive them [[cite:cf.&Naab17]]. In contrast,
cosmological hydrodynamical simulations have made significant strides
in recent years, incorporating semi-analytical models which simulate
star formation and feedback effects at small scales, enabling
exploration of various galaxy-formation scenarios
[[citep:e.g.&Pillepich17;&Weinberger16;&Vogelsberger14]].

Despite the apparent benefits of directly integrating these galaxy
models to lens modelling, the already difficult computational and
algorithmic challenges persist. However, it has been shown that deep
learning neural networks are universal approximators
[[citep:&Hornik89;&Kratsios20]], and often outperform conventional,
computationally complex operations in efficiency and accuracy. Hence,
I propose a novel data-driven deep learning approach to lens modelling
that generates deflection fields directly from 3D galaxy models
sampled from hydrodynamical simulations. \\
While there were previous attempts at harnessing realistic galaxy
models from hydrodynamical simulations [[citep:see&Adam22;&Denzel21]],
these studies used predetermined 2D projections at fixed orientations
of the galaxy. The novelty in this proposal lies in the direct
processing of the 3D data from such galaxy models as input to a deep
neural network architecture, which essentially serves as a data
augmentation method. This approach allows for an increase in possible
lens model fits due to the multiplicity of orientations from which a
galaxy model can be projected onto a 2D plane (as shown by these
previous studies).

In astrophysical, hydrodynamical simulations, the commonly-used data
format is called /smooth-particle hydrodynamics/
[[citep:&Gingold77;&Lucy77;&Monaghan92]]. Basically, the same data
type is referred to as /point clouds/ in the computer vision
field. They are most commonly produced by LiDARs, 3D scanners, or
multi-channel depth camera systems. Parsing and knowledge extraction
from point cloud data is considered an exceptionally difficult task as
they are fundamentally unstructured data
[[citep:cf.&Vinyals2015;&Armeni16;&Rufus20;&Zhang15;&Nuechter07;&Rusinkiewicz00]].
[[cite:&Qi16]] pioneered deep learning with 3D point cloud data, and
subsequent studies built upon this idea
[[citep:see&Qi17;&BenShabat17;&Klokov17;&Kaul21;&AbadRocamora22]]. \\
At the same time, recent studies by [[cite:&Quessard20;&Keurti22]]
demonstrate the feasibility of efficiently learning spatial group
operators, such as rotation, through regularization and mapping of the
latent space with neural networks.

Integrating computer vision deep learning techniques with
astrophysical data within the context of gravitational lensing poses a
significant challenge, but holds the potential for substantial
scientific advancement across all disciplines.

*** Project description


**** Goals & expected results
<<sec:goals>>

The main objectives of this research are:
#+ATTR_LATEX: :options [leftmargin=*, noitemsep]
1) To develop a generative deep learning model that can efficiently
   and accurately predict gravitational lensing deflection fields from
   a 3D galaxy model, optimizing for its orientation.
   #+ATTR_LATEX: :options [leftmargin=*]
   - To this end, we construct a custom training dataset of
     ray-traced, synthetic lenses from observed source images, such as
     quasars, and manually projected galaxy models from publicly
     available hydrodynamical simulation suites
     [[citep:&Springel17;&Nelson18;&Dave19]].
2) To embed the generative deep learning model in a (for the most part
   autonomous) Bayesian lens modelling framework analogous to
   [[cite:&Adam22;&Denzel21;&Morningstar19;&Hezaveh17]] to fit
   observations for galaxy models.
   #+ATTR_LATEX: :options [leftmargin=*]
   - We will compare its accuracy and efficiency against existing lens
     modelling and source reconstruction techniques. Note that the
     proposed scheme will be able to directly draw conclusion on the
     3D structure of lenses, which is a novel capability no other
     existing lens modelling tool possesses.
   - This test can be performed with corresponding gravitational lens
     datasets from surveys such as the Strong Lensing Legacy Survey
     [[citep:SL2S:&Gavazzi12;&Sonnenfeld15]], the Sloan Lens ACS
     Survey [[citep:SLACS:&Bolton2006;&Shu17]], or the Baryon
     Oscillation Spectroscopic Survey (BOSS) Emission-Line Lens Survey
     [[citep:BELLS:&Brownstein11;&Shu2016]].
3) To test the generative lens modelling scheme on new unseen
   gravitational lens observations in a "real-world" setting, and to
   investigate the relative impact of 3D dark matter distributions,
   galaxy shape, orientation, galaxy formation scenarios, and other
   properties on these observations.\footnote{This could also be considered part of a follow-up project.}

**** Methods
<<sec:methods>>
Formally, the deflection field $\bm\alpha(\bm\theta, \xi)$ can be
expressed through a given angle on the observer's sky $\bm\theta$, and
an orientation $\xi$ of the 3D density $\rho(\bm\theta,z)$. The
convergence map (that is, the lensing mass distribution in
dimensionless form) is given by the usual projection of the 3D mass
density as
\begin{equation}\label{eq:thinlens}%
  \kappa(\bm\theta,\xi) = \frac{4\pi G}{cH_0}\, \frac{D_\mathrm{LS}D_\mathrm{L}}{D_\mathrm{S}} \int \rho(\bm\theta,\xi,z)\,\mathrm{d}z \,.
\end{equation}
Here, $D_{LS}$ is the dimensionless angular-diameter distance from the
lens to the source, $D_L$ and $D_S$ are analogous.  Through the
Poisson equation, we can connect the deflection field in
Equation@@latex:~@@\eqref{eq:thinlens} to the convergence as
\begin{equation}\label{eq:deflection_field}%
  \bm\alpha(\bm\theta,\xi) = \nabla_{\bm\theta}\psi(\bm\theta,\xi) = 2\nabla_{\bm\theta}^{-1}\kappa(\bm\theta,\xi) \,.
\end{equation}
Angular positions on the source plane $\bm\beta$ are connected to the
image plane positions $\bm\theta$ through the ray-tracing lens
equation
\begin{equation}\label{eq:lens_equation}%
  \bm\beta = \bm\theta - \bm\alpha \,.
\end{equation}
This translates to a mapping between image and source plane
$L(\bm\theta, \bm\beta)$ that can be discretized in matrix form
according to
\begin{equation}%
  I(\bm\theta) = \int L(\bm\theta, \bm\beta) s(\bm\beta) \mathrm{d^{2}}\bm\beta\,,
\end{equation}
where $s(\bm\beta)$ source-brightness and $I(\bm\theta)$
image-brightness distributions; see Appendix A and B in
[[cite:&Treu2004]] for details on how to construct this matrix.

Forward modelling these equations is trivial and can be accomplished
with well-established algorithms such as Fast Fourier Transform,
multi-grid, or iterative relaxation methods. \\
Solving the inverse problem is considerably more challenging however,
and requires convex optimization involving repeated, computationally
expensive operations such as matrix inversions. This task is further
complicated if the orientation of the 3D galaxy density distribution
in
Equations@@latex:~@@\eqref{eq:deflection_field}@@latex:~@@&@@latex:~@@\eqref{eq:lens_equation}
has to be marginalized.

My proposed technique controls these optimizations using conditional,
generative neural networks. There are various deep learning approaches
which can deal with such problems, each with advantages and
trade-offs:
#+ATTR_LATEX: :options [leftmargin=*, noitemsep]
- VAEs [[citep:&Kingma13]] are considered fast, and explicitly
  construct a latent representation of the input, but trade accuracy
  for the sake of prior matching.
- Normalizing flows [[citep:&Rezende15]] parametrize a diffeomorphism
  with a neural network and approximate likelihoods from the
  input. Since diffeomorphisms are bijective, the mapping from input
  to output is invertible, but is typically expensive in
  high-dimensional problems (such as image mappings from 3D models).
- GANs [[citep:&Goodfellow14]] play a minimax game between a generator
  network and a discriminator network critiques the generator during
  training. They tend to be fast during inference and generate
  high-quality outputs, but are prone to the issue of mode collapse.
- Autoregressive models [[citep:&Parmar18]] have been shown to consistently outperform
  other types of models when it comes to accuracy, but tend to be
  extremely slow, especially during inference.
- Diffusion models [[citep:&Sohl-Dickstein15;&Ho20]] are latent
  variable models whose variables keep the dimensionality of the input
  data. Inspired by the physical effect of the same denomination, the
  approximate posterior is fixed to a Markov chain with Gaussian noise
  transitions. These models have recently shown great success in
  generating high-quality samples, but similar to autoregressive
  models are slow in comparison to GANs or VAEs.

The choice of deep learning architecture and method will ultimately
depend on the accuracy and scalability to the lensing galaxy data, and
has to be investigated.

**** Approach

The project is organized in a work package of sequential tasks
(WP[1-5]) as follows:

#+ATTR_LATEX: :options [leftmargin=*, noitemsep]
- WP1: /gathering publicly available base datasets/
  #+ATTR_LATEX: :options [leftmargin=*]
  1) source plane images of quasars (QSOs) from the Sloan Digital Sky
     Survey Quasar Catalog [[citep:&Schneider10;&Paris18]] and other
     sources [[citep:&Flesch21]]. In total, these catalogs have over a
     million classified type-I/II QSO entries, but for this project
     only a small sub-sample around 1'000--10'000 at preferentially
     higher redshifts should suffice.
  2) lensing galaxy models (3D) from the /IllustrisTNG/
     [[citep:&Nelson18]] and /simba/ [[citep:&Dave19]] simulation
     suites.  These are available as raw HDF5 data at up to 2.7 TB per
     snapshot containing roughly 3000 appropriate galaxy models. Again,
     roughly 3-4 snapshots should suffice and fit on the available
     storage devices.
  3) the test datasets SL2S, SLACS, and BELLS (see
     Section@@latex:~@@\ref{sec:goals}) have a direct comparison with
     corresponding existing lens modelling tools. Here, only a small
     subset is needed corresponding to the samples tested in the
     studies by [[cite:&Adam22;&Denzel21;&Morningstar19;&Hezaveh17]].
- WP2: /building the training dataset/
  #+ATTR_LATEX: :options [leftmargin=*]
  - simulated lens images and deflection fields from the base datasets
    in WP1. These can be simulated with existing, open-source software
    (see Section@@latex:~@@\ref{sec:research}), but as explained in
    Section@@latex:~@@\ref{sec:methods} could easily be implemented
    to run on the available NVIDIA A100 GPU cluster available to us.
- WP3: /testing and training deep learning architecture/
  #+ATTR_LATEX: :options [leftmargin=*]
  - this is the most compute-intensive task and will be run in parallel
    on our GPU science cluster of 8 NVIDIA A100 GPUs. The network
    architectures mentioned in Section@@latex:~@@\ref{sec:methods} are
    readily available on GitHub, but in most cases will have to be
    adjusted to fit our particular data specifications.
- WP4: /integration into a lens modelling framework/
  #+ATTR_LATEX: :options [leftmargin=*]
  - strategies from studies mentioned in WP2 may be adapted for this
    purpose, or a new strategy could be explored.
- WP5: /benchmarking and real-world testing/
  #+ATTR_LATEX: :options [leftmargin=*]
  1) benchmarking the generative lens modelling performance on the
     test dataset and comparison of the results with existing lens
     modelling techniques mentioned above.
  2) once proof-of-concept has been established, the generative lens
     modelling scheme can be tested on new gravitational lens
     observations in a "real-world" setting, such as lens candidates
     from [[cite:&Huang21;&Storfer22]].


**** Possible risks

The potential risks of this project mainly comprise of undesirable
outcomes which either impact the model's autonomy and efficiency, or
extend the project timeline due to additional work, but can be
ameliorated:
#+ATTR_LATEX: :options [leftmargin=*, noitemsep]
- The principal idea of the proposed method relies on the degeneracy
  problem in lens systems. While in theory there should be an infinite
  amount of lens solutions to a particular observations, the selected
  training dataset may not be large enough for the true data
  distribution. In that case, the training dataset may need to be
  reworked.
- Previous attempts to integrate 3D point-cloud data into the
  aforemention deep learning models have been met with challenges and
  considerable trade-offs in efficiency at times. Poor choices in
  architecture and model design could prevent the proposed technique
  from being scalable for large datasets.
- In addition, deep learning is often categorized as black-box model,
  and it is necessary to take significant caution when presenting any
  results from a deep generative model. To increase its trustworthiness,
  well-established methods such as saliency maps, surrogate modelling,
  or uncertainty estimation should be employed. Moreover, the deep
  learning model should be designed for robustness against noise (and
  adversarial examples). If these considerations are not sufficiently
  addressed, the lens modelling community may not accept any results
  from the method.

**** Potential impact

Demonstrating the feasibility of the proposed method would mark a
significant achievement as it would be the first instance of a
strong-lensing modelling technique capable of directly inferring 3D
matter distributions and its individual components (dark matter,
stars, gas, and dust).  In particular, it will model the first-ever 3D
map of a dark matter halo for strong-lens observations, a crucial,
still missing component for studying the astrophysical and
cosmological properties of our Universe. \\
Moreover, the method could provide prior constraints for time-delay
tomography, possibly enabling a much-needed determination of the
Hubble constant at the 1%-precision level. \\
Designed with efficiency in mind, the method is also capable of
autonomously processing vast amounts of new lensing data. This is
especially critical in light of the gravitational lens discoveries
anticipated from next-generation telescopes, such as SKA or Euclid.


#+LATEX: \newpage
** Bibliography

# Bibliography ################################################################
# [[bibliographystyle:plainnat][Bibliography style]]
# [[bibliographystyle:unsrtnat][Bibliography style]]
[[bibliographystyle:apsrev][Bibliography style]]
[[bibliography:./gl3dgen.bib][Bibliography file]]
